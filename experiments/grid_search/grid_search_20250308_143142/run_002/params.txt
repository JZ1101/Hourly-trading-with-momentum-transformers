{
    "seq_length": 55,
    "patience": 25,
    "num_layers": 6,
    "num_heads": 16,
    "learning_rate": 0.0001,
    "hidden_dim": 128,
    "dropout": 0.1,
    "batch_size": 64
}